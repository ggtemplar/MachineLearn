{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Project\n",
    "The following notebook is about developing an end to end machine learning project, going over the different aspects of the process. Here we have chosen the example of predicting house price given then `real estate data`.<br>\n",
    "\n",
    "## Step 1: Framing the problem\n",
    "Be clear so as to what is the end goal. Know what will the output of our model be used for: Will it be used directly as an end result or will it be fed to another machine learning system. Knowing these things helps us decide what measure of accuracy is required in the result, which algorithms should be used, which performace measure should be selected, how much time and resources do we need to spend on maing the model etc.<br>\n",
    "\n",
    "Development of a system usually requires `pipelines` in machine learning. A sequence of data processing components is called a data pipeline. Components typically run asynchronously. Each component pulls in a large amount of data, processes it and spits out the result into another data store, which is then pulled in by the next component. Each component is self contained and interfaced only via data-stores. This system allows different teams to work on different aspects of the project and also makes it more robust beacause if one component breaks down, others can still function for some time.<br>\n",
    "\n",
    "Another important thing we can search is whether or not there are existing solutions to the problem, which can help us gain insights. After considering the above facts, we start framing a problem in terms of whether it will be a supervised, unsupervised or reinforcement learning? Is it a classification task, regression task or somemthing else? Should be use batch learning or online learning? For our project we can clearly see it is going to be a `supervised learning` task since we are given labeled training examples. (each instance comes with an expected output feature). It is also going to be a `multivariate-regression` task since we are being asked to predict using multiple features. And finally since we have a census data, it has to be `batch learning`. (no continous data).<br>\n",
    "\n",
    "Techniques such as `MapReduce` are also used to split batch learning work across multiple servers.\n",
    "\n",
    "## Step 2: Select a performance measure\n",
    "Typical performance measures for a regression task include:<br>\n",
    "\n",
    "**Root Mean Square Error (RMSE):** $\\text{RMSE}(\\mathbf{X}, h) = \\sqrt{\\frac{1}{m}\\sum\\limits_{i=1}^{m}\\left(h(\\mathbf{x}^{(i)}) - y^{(i)}\\right)^2}$ where, <br>\n",
    "$m = $ number of instances.<br> $\\mathbf{x}^{(i)} = $ a vector representing all the features of the ith instance of the data set.<br> $y^{(i)} = $ the label corresponding to the ith instance.<br> $\\mathbf{X} = {(\\mathbf{x}^{(i)})}^T$ i.e A matrix whose every row vector represents the features of the ith instance.<br> $h = $ the prediction function of our system.<br> $\\text{RMSE}(\\mathbf{X}, h) = $ the cost function.<br>\n",
    "\n",
    "**Mean Absolute Error (MAE):** $\\text{MAE}(\\mathbf{X}, h) = \\frac{1}{m}\\sum\\limits_{i=1}^{m}\\left|h(\\mathbf{x}^{(i)}) - y^{(i)}\\right|$<br>\n",
    "\n",
    "Although we might want to use **RMSE** for regression tasks, it is not favourible if there are too many outliers in our data.<br>\n",
    "\n",
    "Both **RMSE** and **MAE** are ways to measure distance between two vectors: `prediction vector` and the `target vector`, called `norms.` **RMSE** corresponds to the `Euclidian norm` or $l_2$ norm, **MAE** corresponds to the `Manhattan norm` or the $l_1$ norm. More generally $l_k$ norem of a vector $\\mathbf{v}$ containing $n$ elements is defined as: $\\left\\| \\mathbf{v} \\right\\| _k = (\\left| v_0 \\right|^k + \\left| v_1 \\right|^k + \\dots + \\left| v_n \\right|^k)^{\\frac{1}{k}}$. $l_0$ gives the number of non-zero elements in the vector whereas $l_\\infty$ gives the maximum value in the vector. Higher norm indices focus on larger values.\n",
    "\n",
    "## Step 3: Check the Assumptions\n",
    "It's always good to cross check the assumptions with the goal so that months of work is not wasted incase we ended up using a wrong algorithm. \n",
    "\n",
    "## Step 4: Downloading Data and Utility Tasks\n",
    "### 4.1 Imports\n",
    "These modules will be used throughout the project thus we import them first, the other imports are done as we go further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility imports to handle os specific tasks.\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Import for downloading the data sets.\n",
    "import urllib\n",
    "\n",
    "# For visualizing data.\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Inline plots as opposed to plots in new windows.\n",
    "%matplotlib inline\n",
    "\n",
    "# Pretty plots.\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Imports for crucial data structures and pseudo-random generation.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To make the output stable across runs.\n",
    "np.random.seed(42)\n",
    "\n",
    "# This is done for cross platform compatibility.\n",
    "root_directory = \".\"\n",
    "chapter = \"end_to_end_project\"\n",
    "\n",
    "# os.join(path, *paths) is used to concatenate passed strings to form a path.\n",
    "images_path = os.path.join(root_directory, \"images\", chapter)\n",
    "\n",
    "# A Utility function to save the generated figures as png files.\n",
    "# +------------------------------------------------------------------------+\n",
    "# | parameter     | type    | Comment                                      |\n",
    "# +------------------------------------------------------------------------+\n",
    "# | fig_id        | string  | Takes the figure name.                       |\n",
    "# | tight_layout  | boolean | Decide whether to use tight_layout() or not. |\n",
    "# | fig_extension | string  | Sets image extension type.                   |\n",
    "# | resolution    | integer | Stores the dpi.                              |\n",
    "# -------------------------------------------------------------------------+\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    \n",
    "    # Construct the image path.\n",
    "    path = os.path.join(images_path, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    \n",
    "    # Allows subplots to fit in the figure area.\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # matplotlib.pyplot.savefig(*args, **kwargs)\n",
    "    # Some of the parameters include:\n",
    "    # 1. fname: string or file-like object, in our case it is the path of the figure.\n",
    "    # 2. dpi: interger value, dots per inch (resolution).\n",
    "    # 3. format: string, contains the file extension.\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Aquisition\n",
    "We shall now download the data sets required for our project from the `handson-ml` repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to fetch our data set.\n",
    "repo_url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "data_url = repo_url + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "# Path to our data on the system.\n",
    "data_path = os.path.join(\"datasets\", \"housing\")\n",
    "\n",
    "# A utility function to download and extract the data set from the repository.\n",
    "def fetch_housing_data(housing_url=data_url, housing_path=data_path):\n",
    "    \n",
    "    # Create a directory if it does not exist.\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    \n",
    "    # Full path to our downloaded archive.\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    \n",
    "    # Download request for our data set.\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    \n",
    "    # Opens the tarfile in 'read-only' mode as default, returning a TarFile Object.\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    \n",
    "    # extractall(path) takes the path as a string parameter and extracts the contents of the archive.\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the data set into our program.\n",
    "def load_housing_data(housing_path=data_path):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    \n",
    "    # Returns a pandas DataFrame object.\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 A Look at the structure of Data\n",
    "From a quick look at the first few entries using the `pandas.DataFrame.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>4.0368</td>\n",
       "      <td>269700.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.84</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>3.6591</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.84</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>3.1200</td>\n",
       "      <td>241400.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-122.26</td>\n",
       "      <td>37.84</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>2.0804</td>\n",
       "      <td>226700.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.84</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3549.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>3.6912</td>\n",
       "      <td>261100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "5    -122.25     37.85                52.0        919.0           213.0   \n",
       "6    -122.25     37.84                52.0       2535.0           489.0   \n",
       "7    -122.25     37.84                52.0       3104.0           687.0   \n",
       "8    -122.26     37.84                42.0       2555.0           665.0   \n",
       "9    -122.25     37.84                52.0       3549.0           707.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
       "5       413.0       193.0         4.0368            269700.0        NEAR BAY  \n",
       "6      1094.0       514.0         3.6591            299200.0        NEAR BAY  \n",
       "7      1157.0       647.0         3.1200            241400.0        NEAR BAY  \n",
       "8      1206.0       595.0         2.0804            226700.0        NEAR BAY  \n",
       "9      1551.0       714.0         3.6912            261100.0        NEAR BAY  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = load_housing_data()\n",
    "\n",
    "# DataFrame.head(n=5), n:integer, number of entries to be shown.\n",
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the first few rows of our real estate data. As we can see, each row has 1`ten attributes`. We can generate information about this `DataFrame` using the `pandas.DataFrame.info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
